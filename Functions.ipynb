{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file consists of function codes for extracting features\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from googletrans import Translator\n",
    "import mysql.connector\n",
    "import urllib.parse\n",
    "import html\n",
    "import requests\n",
    "from DB import *\n",
    "from collections import Counter  # for getting most common item in a list\n",
    "import whois\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import ssl,socket\n",
    "import geoip2.database\n",
    "from googlesearch import search\n",
    "from apiclient.discovery import build # for Google's custom search engine API\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "from cryptography import x509  # from external package cryptography\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.x509.oid import ExtensionOID\n",
    "from cryptography.x509.oid import NameOID\n",
    "\n",
    "\n",
    "def checkShortURLs(url, cur):\n",
    "    shortURLExist = 0\n",
    "    FQDN = url.split(\"/\",3)[2]\n",
    "    urlServices = getShortURLServices(cur)\n",
    "    for service in urlServices:\n",
    "        if FQDN ==  service[0] :\n",
    "            shortURLExist = 1\n",
    "            break\n",
    "    return shortURLExist\n",
    "\n",
    "\n",
    "def getHostname(URL) :\n",
    "    if len(re.findall(r'.*?/.*?',URL)) == 2:    # URL for cases like http://www.parkrun.com?cb=31537\n",
    "        hostname = URL.split(\"/\",2)[2]    # split with the 2nd '/' and take the 3rd string value while removing a url path. We remain with the FQDN\n",
    "    if len(re.findall(r'.*?/.*?',URL)) >= 3:    \n",
    "        hostname = URL.split(\"/\",3)[2]    # split with the 3rd '/' and take the 3rd string value while removing a url path. We remain with FQDN\n",
    "    return hostname\n",
    " \n",
    " \n",
    "def getURLPath(URL):   \n",
    "    if len(re.findall(r'.*?/.*?',URL)) == 2:    # URL for cases like http://www.parkrun.com?cb=31537\n",
    "        URL_path = ''\n",
    "    if len(re.findall(r'.*?/.*?',URL)) >= 3:    \n",
    "        URL_path = URL.split(\"/\",3)[3]\n",
    "    return URL_path\n",
    "     \n",
    "\n",
    "def check_IP4_in_hostname(hostname) :    \n",
    "    if re.search (r'.*?\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}.*?', hostname, re.I) :\n",
    "        IP4_exist = 'Yes'\n",
    "    else :\n",
    "        IP4_exist = 'No'\n",
    "    return IP4_exist\n",
    "\n",
    "\n",
    "def count_numerics_in_URL(URL) : \n",
    "    hostname = getHostname(URL)\n",
    "    count_hostname = 0\n",
    "    for char in hostname :\n",
    "        if char.isdigit():\n",
    "            count_hostname = count_hostname + 1\n",
    "    URL_path = getURLPath(URL)\n",
    "    count_path = 0\n",
    "    for char in URL_path :\n",
    "        if char.isdigit():\n",
    "            count_path = count_path + 1\n",
    "    return count_hostname, count_path\n",
    "     \n",
    "    \n",
    "def detectRedirectionByRequests(URL,webpage,cur,shortURLFound):\n",
    "    time_ShortURL1 = time.time() \n",
    "    shortURLExist = checkShortURLs(URL,cur)   # check if the source url is of a known short url service\n",
    "    if shortURLExist == 1:\n",
    "        shortURLFound = 'Yes'\n",
    "    time_ShortURL2 = time.time() \n",
    "    time_ShortURL = round((time_ShortURL2 - time_ShortURL1), 5)\n",
    "    # check for server based redirection. NOTE others are client based redirections\n",
    "    if len(webpage.history) > 0:   # redirection is detected       \n",
    "        noRedirections = len(webpage.history)\n",
    "        URL1 = webpage.url    # the final redirected URL       \n",
    "    if len(webpage.history) == 0: \n",
    "        URL1 = URLs\n",
    "        shortURLExist = 0\n",
    "        noRedirections = 0\n",
    "    return URL1,shortURLExist,noRedirections,shortURLFound,time_ShortURL\n",
    "\n",
    "\n",
    "def detectMetaURLRedirections(url,webpage,soup):\n",
    "    try:\n",
    "        contentValue = soup.find('meta', attrs={'http-equiv':re.compile(\"refresh\", re.I)})['content']    # value 'refresh' may be written in capital letter(s) to obfuscate some detection, so ignore cases should be used. Here we get the value of the attribute 'content'\n",
    "        if re.search (r'(......http://.*?)',contentValue, re.I) or re.search (r'(......https://.*?)',contentValue, re.I):     # if the URL value is NOT in quote\n",
    "            url = contentValue.split(\"=\",1)[1]   # split with the first =\n",
    "            noRedirections2 = 1\n",
    "        elif re.search (r'(.......http://.*?)',contentValue, re.I) or re.search (r'(.......https://.*?)',contentValue, re.I):     # if the URL value is in quote\n",
    "            url = contentValue.split(\"'\",1)[1]   # split with the first '\n",
    "            noRedirections2 = 1\n",
    "        elif re.search (r\"(.....='.*?')\",contentValue, re.I):\n",
    "            path = contentValue.split(\"'\",1)[1]    # if the value of URL path is in quotes, split with the first ' \n",
    "            url = url + path\n",
    "            noRedirections2 = 1\n",
    "        elif re.search (r\"(.....=.*?)\",contentValue, re.I):\n",
    "            path = contentValue.split(\"=\",1)[1]    # if the value of URL path is NOT in  quotes, split with the first = \n",
    "            url = url + path\n",
    "            noRedirections2 = 1\n",
    "        else:     # the content value may be just a number (time)\n",
    "            noRedirections2 = 0\n",
    "    except TypeError as e:\n",
    "        noRedirections2 = 0\n",
    "    if url.startswith(\"'\") and url.endswith(\"'\") :\n",
    "        url = url.split(\"'\",2)[1]\n",
    "    return url,noRedirections2\n",
    "\n",
    "\n",
    "def detectJavaScriptRedirection(URL,soup):\n",
    "    texts = ''\n",
    "    JSredirect = 'Yes'\n",
    "    if soup.find('script') is not None:\n",
    "        for tag in soup.findAll('script'):\n",
    "            texts  =texts + tag.text\n",
    "    if re.search(r'window.location=\"(.*?)\"',texts,re.I):\n",
    "        url = re.findall(r'window.location=\"(.*?)\"',texts)[0]\n",
    "    elif re.search(r'window.location.replace\\(\"(.*?)\"\\)',texts,re.I):\n",
    "        url = re.findall(r'window.location.replace\\(\"(.*?)\"\\)',texts)[0]\n",
    "    else:\n",
    "        url = URL\n",
    "        JSredirect = 'No'\n",
    "    if re.search (r'https?://.*?',url, re.I) is None :\n",
    "        FQDN = URL.split('/',3)[2]\n",
    "        url = URL.split('/',3)[0] + '//'  + URL.split('/',3)[2] + '/' + url\n",
    "    return url,JSredirect\n",
    "\n",
    "\n",
    "def detectAllURLRedirections(URL,webpage,cur,soup,headers):  # some of the redirections, for instance designed in the server, can not be detected by this method\n",
    "    url = URL  # url is the original URL\n",
    "    noRedirections = 0\n",
    "    redirectType = ''\n",
    "    check = True\n",
    "    shortURLFound = 'No'\n",
    "    while check : # checking on the chain redirections\n",
    "        webpage = requests.get(URL,verify=False,headers=headers)\n",
    "        URL1,shortURLExist1,noRedirections1,shortURLFound,time_ShortURL = detectRedirectionByRequests(URL,webpage,cur,shortURLFound)  # check redirections detected by requests lib\n",
    "        if URL1 != URL and shortURLExist1 == 'Yes' :\n",
    "             redirectType = redirectType + 'Short-Long URL, '   \n",
    "             noRedirections = noRedirections + noRedirections1\n",
    "        if URL1 != URL and shortURLExist1 == 'No' :\n",
    "             redirectType = redirectType + 'Others (client end), '   \n",
    "             noRedirections = noRedirections + noRedirections1\n",
    "         \n",
    "        webpage = requests.get(URL1,verify=False,headers=headers)  \n",
    "        soup = BeautifulSoup(webpage.content,'html.parser')\n",
    "        URL2,noRedirections2 = detectMetaURLRedirections(URL1,webpage,soup) # check redirections assigned in the meta tag\n",
    "        if URL2 != URL1:\n",
    "            redirectType = redirectType + 'Meta Tag, '\n",
    "            noRedirections = noRedirections + noRedirections2\n",
    "            \n",
    "        try:\n",
    "            webpage = requests.get(URL2,verify=False,headers=headers)  \n",
    "            soup = BeautifulSoup(webpage.content,'html.parser')\n",
    "            URL3,JSredirect = detectJavaScriptRedirection(URL2,soup) # check redirections by javascript\n",
    "            if URL3 != URL2:\n",
    "                redirectType = redirectType + 'JavaScript, '\n",
    "                noRedirections = noRedirections + 1\n",
    "            URL = URL3\n",
    "        except requests.exceptions.MissingSchema as e:\n",
    "            URL = URL2\n",
    "            URL3 = URL2\n",
    "            pass \n",
    "        except requests.exceptions.InvalidSchema as e:\n",
    "            URL = URL2\n",
    "            URL3 = URL2\n",
    "            pass    \n",
    "        if URL1 == URL and URL2 == URL1 and URL3 == URL2:\n",
    "            check = False    \n",
    "    if url != URL3 and noRedirections == 0 :\n",
    "        redirectType = 'Server end'\n",
    "        noRedirections = 1\n",
    "    return url,URL3,noRedirections,redirectType,shortURLFound,time_ShortURL  \n",
    "    \n",
    "\n",
    "def checkWebpageType(webpage2):\n",
    "    page_type = str(webpage2.headers['content-type'])\n",
    "    if ('html'  in page_type) or ('htm'  in page_type) or ('json'  in page_type) or ('javascript'  in page_type) or ('xml'  in page_type):    # at least one of the format is a substring of a page's content type\n",
    "        validPage = 'True'\n",
    "    else:\n",
    "        validPage = 'False'\n",
    "    return validPage,page_type\n",
    "\n",
    "\n",
    "def checkFormInputTags(soup):\n",
    "    formChecker = 'Yes'\n",
    "    inputChecker = 'Yes'\n",
    "    countText = 0\n",
    "    countEmail = 0\n",
    "    countTel = 0\n",
    "    countDate = 0\n",
    "    countMonth = 0\n",
    "    countPass = 0\n",
    "    noPrompts = 0\n",
    "    noWindowPrompts = 0\n",
    "    noPopupWindow = 0\n",
    "    noJSPrompts = 0\n",
    "    if soup.find('form') is None:\n",
    "        formChecker = 'No'\n",
    "    if soup.find('input') is None:\n",
    "        inputChecker = 'No'\n",
    "    else:    # if there is at least one input tag\n",
    "        for tag in soup.findAll('input'):\n",
    "            if tag.get('type') =='text': \n",
    "                countText = countText+1\n",
    "            if tag.get('type') =='email': \n",
    "                countEmail = countEmail+1\n",
    "            if tag.get('type') =='tel': \n",
    "                countTel = countTel+1\n",
    "            if tag.get('type') =='date': \n",
    "                countDate = countDate+1\n",
    "            if tag.get('type') =='month': \n",
    "                countMonth = countMonth+1\n",
    "            if tag.get('type') == 'password':\n",
    "                countPass = countPass+1\n",
    "    if soup.find('script') is not None:\n",
    "        for tag in soup.findAll('script'):\n",
    "            tagText = tag.text\n",
    "            noPrompts = noPrompts + len(re.findall(r'prompt\\(.*?\\)', tagText)) # to include ( or ) in the search, we should use \\ before the character otherwise ( and ) are treated as boundaries of search i.e only characters between them will be searched.\n",
    "            noWindowPrompts = noWindowPrompts + len(re.findall(r'window.prompt\\(.*?\\)',tagText)) # one script tag may contain multiple prompts\n",
    "            noPopupWindow = noPopupWindow + len(re.findall(r'popup', tagText)) # one script tag may contain multiple popups\n",
    "            noJSPrompts = noPrompts + noWindowPrompts + noPopupWindow\n",
    "    return formChecker,inputChecker,countText,countEmail,countTel,countDate, countMonth,countPass,noPrompts,noWindowPrompts,noPopupWindow,noJSPrompts\n",
    "\n",
    "\n",
    "def checkSearchForm(soup):\n",
    "    seachFormExist = 'No'\n",
    "    if soup.find('form',attrs={'id':re.compile(\".*?search.*?\", re.I)}) or soup.find('form',attrs={'class':re.compile(\".*?search.*?\", re.I)})  or soup.find('form',attrs={'action':re.compile(\".*?search.*?\", re.I)}) :\n",
    "        seachFormExist = 'Yes'\n",
    "    if soup.find('input',attrs={'id':re.compile(\".*?search.*?\", re.I)}) or soup.find('input',attrs={'class':re.compile(\".*?search.*?\", re.I)}) or soup.find('input',attrs={'placeholder':re.compile(\".*?search.*?\", re.I)}) or soup.find('input',attrs={'value':re.compile(\".*?search.*?\", re.I)}) or soup.find('input',attrs={'placeholder':re.compile(\".*?ask.*?\", re.I)}) or soup.find('input',attrs={'placeholder':re.compile(\".*?question.*?\", re.I)}) :\n",
    "        seachFormExist = 'Yes'\n",
    "    if soup.find('button',attrs={'value':re.compile(\".*?search.*?\", re.I)}) or soup.find('button',attrs={'class':re.compile(\".*?search.*?\", re.I)}) or soup.find('button',attrs={'id':re.compile(\".*?search.*?\", re.I)}) or soup.find('button',attrs={'name':re.compile(\".*?search.*?\", re.I)}) :\n",
    "        seachFormExist = 'Yes'\n",
    "        #print(soup.find('form',attrs={'id':re.compile(\".*?search.*?\", re.I)}).get('id')) \n",
    "    return seachFormExist\n",
    "   \n",
    "         \n",
    "def decodeWebpageContents(webpage2,soup):\n",
    "    if soup.original_encoding == 'utf-8':\n",
    "        content = str(webpage2.content,'utf-8')\n",
    "    elif soup.original_encoding == 'utf-16':\n",
    "        content = str(webpage2.content,'utf-16')\n",
    "    elif soup.original_encoding == 'utf-32':\n",
    "        content = str(webpage2.content,'utf-32')\n",
    "    elif soup.original_encoding == 'cp1252':\n",
    "        content = str(webpage2.content,'cp1252')\n",
    "    elif soup.original_encoding == 'windows-1252':\n",
    "        content = str(webpage2.content,'windows-1252')\n",
    "    elif soup.original_encoding == 'ISO-8859-1':\n",
    "        content = str(webpage2.content,'ISO-8859-1')\n",
    "    elif soup.original_encoding == 'ascii':\n",
    "        content = str(webpage2.content,'ascii')\n",
    "    elif soup.original_encoding == 'latin-1':\n",
    "        content = str(webpage2.content,'latin-1')\n",
    "    else:\n",
    "        content = str(webpage2.content) \n",
    "    content = urllib.parse.unquote(content)   # decode special encoded html characters\n",
    "    content = html.unescape(content)  # converts all named and numeric character references (e.g. &gt;, &#62;, &x3e;) in the string  to the corresponding unicode characters\n",
    "    return content\n",
    "\n",
    "\n",
    "def removeTags(content):\n",
    "    content = re.sub(r'(?is)(<!--.*?-->)', '', content, flags=re.IGNORECASE)  # remove comments\n",
    "    content = re.sub(r'(?is)(<script.*?/script>)', '', content, flags=re.IGNORECASE)  # (?is) - added to ignore case and allow new lines in text\n",
    "    content = re.sub(r'(?is)(<style.*?/style>)', '', content, flags=re.IGNORECASE)\n",
    "    content = re.sub(r'(?is)(<noscript.*?/noscript>)', '', content, flags=re.IGNORECASE)\n",
    "    content = re.sub(r'(?is)(<.*?>)', '', content, flags=re.IGNORECASE) # remove all other tags only, leave their texts\n",
    "    return content\n",
    "\n",
    "\n",
    "def removeWhitespaces(content):\n",
    "    content = content.strip()  # remove the white spaces at the beginning and end of the string only\n",
    "    content = ' '.join(content.split())  # replace all whitespace characters (space, tab, newline etc) with a single space\n",
    "    return content\n",
    "\n",
    "\n",
    "def decodeJavaScriptContents(soup):\n",
    "    scriptTexts = ''\n",
    "    encodedText = ''\n",
    "    for tag in soup.findAll('script'):\n",
    "        scriptTexts = scriptTexts + \" \" + tag.text\n",
    "    if 'document.write(unescape(' in str(scriptTexts):\n",
    "        JSTexts = re.findall(r'document.write\\(unescape(.*?)\\)', scriptTexts)  # returns a list of all appearances of the matched string\n",
    "        for text in JSTexts:\n",
    "            encodedText = encodedText + ' ' + text               \n",
    "    decodedText = urllib.parse.unquote(encodedText)  # decode the encoded html content (in this case from hexadecimal)\n",
    "    return decodedText\n",
    "\n",
    "\n",
    "def checkLanguage(soup,translator,newContent):  \n",
    "    try:\n",
    "        language = soup.html.get('lang')   # catch the error when the attribute lang is missing\n",
    "        if language is None or language == '':\n",
    "            if newContent =='' or newContent is None:\n",
    "                lugha = 'Unknown'\n",
    "            else:\n",
    "                language = translator.translate(newContent[:500]).src   # webpage texts without  tags should be useful in determining the language. NOTE that Google translator limits 5,000 characters per translation at one time. So we just take the first 500 characters\n",
    "                if language is None or language == '':     # if for some reasons such as mixed encoded characters, language can not be known\n",
    "                    titleTexts = soup.title.text      \n",
    "                    language = translator.translate(titleTexts).src\n",
    "                    if language is None or language == '':\n",
    "                        language = 'Unknown'              \n",
    "    except AttributeError as e:    # if lack of attribute 'lang' generates an error\n",
    "        if newContent == '' or newContent is  None:\n",
    "           language = 'Unknown'\n",
    "        else:\n",
    "            language = translator.translate(newContent[:500]).src   \n",
    "            if language is None or language == '':     \n",
    "                titleTexts = soup.title.text     \n",
    "                language = translator.translate(titleTexts).src\n",
    "                if language is None or language == '':\n",
    "                    language = 'Unknown'\n",
    "    return language\n",
    "\n",
    "    \n",
    "def translate(language,newContent,translator):\n",
    "    translatedText = translator.translate(newContent[:4999], dest='en').text      # Google translate limits 5,000 characters per translation.  The assumption here is that it is very unlikely to find a login webpage with more than the limit. Alternatively, is to break down the content in group of maximum of 5000 characters \n",
    "    return translatedText\n",
    "\n",
    "\n",
    "def JavaScriptText(soup):\n",
    "    scriptTexts = ''\n",
    "    for tag in soup.findAll('script'):\n",
    "        if tag.get('type') is None or 'application'  not in tag.get('type'): # texts in script of type 'application/json' contains ambigious and undesired characters\n",
    "            scriptTexts = scriptTexts + \" \" + tag.text\n",
    "    return scriptTexts\n",
    "\n",
    "\n",
    "def checkFreeDomainName(freeDomains, domain):  \n",
    "    for free_domain in freeDomains:\n",
    "        if domain.endswith(free_domain[0]) :  # check if the domain ends with a free domain name\n",
    "            freeDomainUsed = 'Yes'\n",
    "            FREEDomain = free_domain[0]\n",
    "            break\n",
    "        else:\n",
    "            freeDomainUsed = 'No'\n",
    "    if freeDomainUsed == 'No':\n",
    "        FREEDomain = ''\n",
    "    return freeDomainUsed,FREEDomain\n",
    "\n",
    "\n",
    "def getURLPrefix(URL):\n",
    "    URLPrefix = URL.split(\":\",1)[0]\n",
    "    return URLPrefix\n",
    "\n",
    "\n",
    "def defineURLComponents(URL):\n",
    "    if len(re.findall(r'.*?/.*?',URL)) == 2:    # URL for cases like http://www.parkrun.com?cb=31537\n",
    "        FQDN = URL.split(\"/\",2)[2]    # split with the 2nd '/' and take the 3rd string value while removing a url path. We remain with FQDN\n",
    "        URL_path = ''\n",
    "    if len(re.findall(r'.*?/.*?',URL)) >= 3:    \n",
    "        FQDN = URL.split(\"/\",3)[2]    # split with the 3rd '/' and take the 3rd string value while removing a url path. We remain with FQDN\n",
    "        URL_path = URL.split(\"/\",3)[3]\n",
    "    # newly added block\n",
    "    if 'www'  in FQDN :\n",
    "        FQDN = FQDN.split('.', 1)[1]   # remove 'www'\n",
    "    return FQDN,URL_path\n",
    "\n",
    "\n",
    "def getDomainIdentity(freeDomains,URL,TLDs):\n",
    "    time_FreeDomain = 0\n",
    "    time_FreeDomain1 = 0\n",
    "    time_FreeDomain2 = 0\n",
    "    count_URLs_FreeDomain = 0\n",
    "    global domainIdentity\n",
    "    if len(re.findall(r'.*?/.*?',URL)) == 2:    # URL for cases like http://www.parkrun.com?cb=31537\n",
    "        domain = URL.split(\"/\",2)[2]    # split with the 2nd '/' and take the 3rd string value while removing a url path. We remain with FQDN\n",
    "        URL_path = ''\n",
    "    elif len(re.findall(r'.*?/.*?',URL)) >= 3:    \n",
    "        domain = URL.split(\"/\",3)[2]    # split with the 3rd '/' and take the 3rd string value while removing a url path. We remain with FQDN\n",
    "        URL_path = URL.split(\"/\",3)[3]\n",
    "        \n",
    "    IPAddressUsed = 'No'\n",
    "    IPAddress = ''\n",
    "    PortNoUsed = 'No'\n",
    "    PortNo = ''\n",
    "    domainIdentity = ''\n",
    "    ccTLDUsed = 'No'\n",
    "    ccTLD = 'Null'\n",
    "    gTLDUsed = 'No'\n",
    "    mainDomain = ''   # only domain name of the webpage\n",
    "    FQDN = domain     # domain name + subdomains\n",
    "        \n",
    "    freeDomainUsed,FREEDomain = checkFreeDomainName(freeDomains,domain)\n",
    "    n = len(domain.split(\".\"))\n",
    "    \n",
    "    if freeDomainUsed == 'Yes':   \n",
    "        domainLevels = len(FREEDomain.split('.')) - 1\n",
    "        m = n - domainLevels\n",
    "        domainIdentity = domain.split(\".\")[-(domainLevels+1)]  # the next domain level after the free domain should be the domain of the user\n",
    "        mainDomain = domainIdentity + FREEDomain\n",
    "    elif freeDomainUsed == 'No':\n",
    "        for tld in TLDs:\n",
    "             if domain.endswith(tld[0]):   # make sure the domain ends with the TLD. In some cases, a ccTLD such as 'co' which is for Colombia may  also be a 2LD in 'co.uk'              \n",
    "                    if tld[1] == 'generic':\n",
    "                        gTLDUsed = 'Yes'\n",
    "                        domainIdentity = domain.split(\".\")[-2]  # one but last string value in the array\n",
    "                        mainDomain = domainIdentity + tld[0]\n",
    "                        break\n",
    "                    if tld[1] == 'country-code':   # few of the TLDS such .tk do not follow the regular structure of the ccTLD e.g .co.tk thus we may need to retrieve 2LD instead of 3LD\n",
    "                        ccTLDUsed = 'Yes'\n",
    "                        ccTLD = tld[0]\n",
    "                        if n == 2:\n",
    "                            domainIdentity = domain.split(\".\")[-2]\n",
    "                            mainDomain = domain\n",
    "                        if n == 3 and 'www' in domain:\n",
    "                            domainIdentity=domain.split(\".\")[-2]\n",
    "                            mainDomain = domainIdentity + tld[0]\n",
    "                        if (n == 3 and 'www' not in domain) or n > 3:\n",
    "                            secondLD = domain.split(\".\")[-2]\n",
    "                            for tld2 in TLDs:    # some of the 2LDs are the same as 1LDs of ccTLDs\n",
    "                                match = 'No'\n",
    "                                if secondLD == tld2[0].split('.')[1]:\n",
    "                                    domainIdentity = domain.split(\".\")[-3]\n",
    "                                    mainDomain = domainIdentity + '.' + secondLD + tld[0]\n",
    "                                    match = 'Yes'\n",
    "                                    break\n",
    "                            if match == 'Yes':\n",
    "                                break\n",
    "                            if len(secondLD) <= 3:   # some of the ccTLDs  use 2LDs such as 'co', 'ac' (which are often in between 2 and 3 character length, though in other few cases it is more than that)\n",
    "                                domainIdentity = domain.split(\".\")[-3]\n",
    "                                mainDomain = domainIdentity + '.' + secondLD + tld[0]\n",
    "                                break\n",
    "                            else:\n",
    "                                domainIdentity = domain.split(\".\")[-2]\n",
    "                                mainDomain = domainIdentity + tld[0]                                                       \n",
    "        if domainIdentity == '' and mainDomain == '':   # the domain does not end with a TLD\n",
    "            try:\n",
    "                domainIdentity = domain.split(\".\")[-2]   # URL for cases like http://www.parkrun.com?cb=31537 where there is no path\n",
    "                domainEnd = domain.split(\".\")[-1]\n",
    "             # if the 1LD contains the number of format of an IP address in various forms\n",
    "                if re.search (r'.*?\\d{1,6}.*?',domainEnd, re.I) or re.search (r'[0-9A-Za-z][0-9A-Za-z]',domainEnd, re.I) or re.search (r'0x[0-9A-Za-z][0-9A-Za-z]',domainEnd, re.I) :  # if the domain ends contains an IP address number in decimal, hexadecimal and octal formats\n",
    "                    if re.search (r'.*?[:]\\d{2,6}',domainEnd, re.I) is None:\n",
    "                        IPAddressUsed = 'Yes'\n",
    "                        domainIdentity = mainDomain = IPAddress = domain\n",
    "                    else:\n",
    "                        domainSubEnd = domainEnd.split(\":\")[0]\n",
    "                        PortNoUsed = 'Yes'\n",
    "                        PortNo = domainEnd.split(\":\")[1]\n",
    "                        FQDN = domain.split(\":\")[0]\n",
    "                        if re.search (r'\\d{1,4}',domainSubEnd, re.I) or re.search (r'0x[0-9A-Za-z][0-9A-Za-z]',domainSubEnd, re.I) :  \n",
    "                            IPAddressUsed = 'Yes'\n",
    "                            domainIdentity = mainDomain = IPAddress = domain.split(\".\")[-4] + '.' +  domain.split(\".\")[-3] + '.' + domain.split(\".\")[-2] + '.' + domainSubEnd\n",
    "                        elif re.search (r'[A-Za-z]+',domainSubEnd, re.I):\n",
    "                            if re.search(r'([0-9A-Za-z][0-9A-Za-z][.][0-9A-Za-z][0-9A-Za-z][.][0-9A-Za-z][0-9A-Za-z][.][0-9A-Za-z][0-9A-Za-z])',domain) :  # if the entire domain has the IP address format\n",
    "                                IPAddressUsed = 'Yes'\n",
    "                                domainIdentity = mainDomain = IPAddress = domain.split(\".\")[-4] + '.' +  domain.split(\".\")[-3] + '.' + domain.split(\".\")[-2] + '.' + domainSubEnd\n",
    "                            else:\n",
    "                                domain2 = domain.split(\":\")[0]\n",
    "                                time_FreeDomain1 = time.time()\n",
    "                                freeDomainUsed,FREEDomain = checkFreeDomainName(freeDomains,domain2)\n",
    "                                time_FreeDomain2 = time.time() \n",
    "                                time_FreeDomain = round((time_FreeDomain2 - time_FreeDomain1) / 3600, 2)\n",
    "                                count_URLs_FreeDomain = count_URLs_FreeDomain + 1\n",
    "                                if freeDomainUsed == 'Yes':   # if the domain contains a free domain name\n",
    "                                    domainLevels = len(FREEDomain.split('.')) - 1\n",
    "                                    m = n - domainLevels\n",
    "                                    domainIdentity = domain2.split(\".\")[-(domainLevels+1)]  # the next domain level after the free domain should be the domain of the user\n",
    "                                    mainDomain = domainIdentity + FREEDomain                                 \n",
    "                                elif freeDomainUsed == 'No':\n",
    "                                    for tld in TLDs:\n",
    "                                         if domain2.endswith(tld[0]):   # make sure the re.search (r'.*?[:]\\d{2,6}',domainEnd, re.I) is None:domain ends with the TLD. In some cases, a ccTLD such as 'co' which is for Colombia may  also be a 2LD in 'co.uk'\n",
    "                                                if tld[1] == 'generic':\n",
    "                                                    gTLDUsed = 'Yes'\n",
    "                                                    domainIdentity = domain2.split(\".\")[-2]  # one but last string value in the array\n",
    "                                                    mainDomain = domainIdentity + tld[0]\n",
    "                                                    break\n",
    "                                                if tld[1] == 'country-code':   # few of the TLDS such .tk do not follow the regular structure of the ccTLD e.g .co.tk thus we may need to retrieve 2LD instead of 3LD\n",
    "                                                    ccTLDUsed = 'Yes'\n",
    "                                                    ccTLD = tld[0]\n",
    "                                                    if n == 2:\n",
    "                                                        domainIdentity = domain2.split(\".\")[-2]\n",
    "                                                        mainDomain = domain2\n",
    "                                                    if n == 3 and 'www' in domain2:\n",
    "                                                        domainIdentity = domain2.split(\".\")[-2]\n",
    "                                                        mainDomain = domainIdentity + tld[0]\n",
    "                                                    if n == 3 and 'www' not in domain2 or n > 3:\n",
    "                                                        secondLD = domain2.split(\".\")[-2]\n",
    "                                                        for tld2 in TLDs:    # some of the 2LDs are the same as 1LDs of ccTLDs\n",
    "                                                            match = 'No'\n",
    "                                                            if secondLD == tld2[0].split('.')[1]:\n",
    "                                                                domainIdentity = domain2.split(\".\")[-3]\n",
    "                                                                mainDomain = domainIdentity + secondLD + tld[0]\n",
    "                                                                match = 'Yes'\n",
    "                                                                break\n",
    "                                                        if match == 'Yes':\n",
    "                                                            break\n",
    "                                                        if len(secondLD) <= 3:   # some of tre.search (r'.*?[:]\\d{2,6}',domainEnd, re.I) is None:he ccTLDs  use 2LDs such as 'co', 'ac' (which are often in between 2 and 3 character length, though in other few cases it is more than that)\n",
    "                                                            domainIdentity = domain2.split(\".\")[-3]\n",
    "                                                            mainDomain = domainIdentity + secondLD + tld[0]\n",
    "                                                            break\n",
    "                                                        else:\n",
    "                                                            domainIdentity = domain2.split(\".\")[-2]\n",
    "                                                            mainDomain = domainIdentity + tld[0]                                                           \n",
    "                else:\n",
    "                    string = '.' + domain.split(\".\")[-1]\n",
    "                    for tld in TLDs:\n",
    "                        pattern = r'' + str(tld[0])\n",
    "                        if tld[1] =='generic':\n",
    "                            gTLDUsed = 'Yes'\n",
    "                            if re.search (pattern,string, re.I) :  # check if any TLD exists in any position of the last part of the domain such as in http://www.parkrun.com?cb=31537\n",
    "                                 mainDomain = domainIdentity + tld[0]\n",
    "                                 break\n",
    "                        if tld[1] =='country-code':    # few of the TLDS such .tk do not follow the regular structure of the ccTLD e.g .co.tk thus we may need to retrieve 2LD instead of 3LD\n",
    "                            if re.search (pattern,string, re.I):  # check if any TLD exists in any position of the last part of the domain such as in http://www.parkrun.com?cb=31537\n",
    "                                ccTLDUsed = 'Yes'\n",
    "                                ccTLD = tld[0]\n",
    "                                if n == 2:\n",
    "                                    mainDomain = domainIdentity + tld[0]\n",
    "                                if n == 3 and 'www' in domain:\n",
    "                                    mainDomain = domainIdentity + tld[0]\n",
    "                                if (n == 3 and 'www' not in domain) or n > 3:\n",
    "                                    secondLD = domain.split(\".\")[-2]\n",
    "                                    for tld2 in TLDs:    # some of the 2LDs are the same as 1LDs of ccTLDs\n",
    "                                        match = 'No'\n",
    "                                        if secondLD == tld2[0].split('.')[1]:\n",
    "                                            domainIdentity = domain.split(\".\")[-3]\n",
    "                                            mainDomain = domainIdentity + '.' + secondLD + tld[0]\n",
    "                                            match = 'Yes'\n",
    "                                            break\n",
    "                                    if match == 'Yes':\n",
    "                                        break\n",
    "                                    if len(secondLD) <= 3:   # some of the ccTLDs  use 2LDs such as 'co', 'ac' (which are often in between 2 and 3 character length, though in other few cases it is more than that)\n",
    "                                        domainIdentity = domain.split(\".\")[-3]\n",
    "                                        mainDomain = domainIdentity + '.' + secondLD + tld[0]\n",
    "                                        break\n",
    "                                    else:\n",
    "                                        domainIdentity = domain.split(\".\")[-2]\n",
    "                                        mainDomain = domainIdentity + tld[0]\n",
    "            except IndexError as e:   # skip the url if it has an invalid format of FQDN in terms of dots e.g http://provide/url/to/app/o2home/in/_conf/externalurls.properties OR other formats of IP address\n",
    "                if re.search(r'(0x[0-9A-Za-z][0-9A-Za-z][0-9A-Za-z][0-9A-Za-z][0-9A-Za-z][0-9A-Za-z][0-9A-Za-z][0-9A-Za-z])',domain,re.I) or re.search(r'(\\d{6,})',domain):   #  IP in hexadecimal format e.g  0x0A056DCF,  dword format e.g  http://235396898359/obscure.htm, in hexa-coded format e.g  http://%70%43%2d%68%45%6c%50%2e%6f%52%67/obscure.htm\n",
    "                    if re.search (r'.*?[:]\\d{2,}',domain, re.I) is None:\n",
    "                        IPAddressUsed = 'Yes'\n",
    "                        domainIdentity = mainDomain = IPAddress = domain\n",
    "                    else:\n",
    "                        PortNo = domain.split(\":\")[1]\n",
    "                        domain2 = FQDN = domain.split(\":\")[0]\n",
    "                        PortNoUsed = 'Yes'                       \n",
    "                        IPAddressUsed = 'Yes'\n",
    "                        domainIdentity = mainDomain = IPAddress = domain2\n",
    "                else:     \n",
    "                    mainDomain = 'Invalid'\n",
    "                    domainIdentity = 'Invalid'                  \n",
    "    return FQDN,domainIdentity,mainDomain,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed,time_FreeDomain,count_URLs_FreeDomain\n",
    "\n",
    "\n",
    "def domainIdentityInWebapge(content,domainIdentity):\n",
    "    contentWithTags = removeWhitespaces(content)\n",
    "    pattern = r'' + str(domainIdentity)\n",
    "    domainIdentityCounts = len(re.findall(pattern,contentWithTags,re.I))\n",
    "    return domainIdentityCounts\n",
    "\n",
    "\n",
    "def domainIdentityInCopyright(soup,domainIdentity):\n",
    "    copyrightTexts = ''\n",
    "    try:\n",
    "        copyrightTexts = soup.find(['div','span', 'p','li','ul','small','a'],attrs={'class':re.compile(\".*?copyright.*?\", re.I)}).text  # if there is one of the mentioned tags with a class attribute of value 'copyright'. Texts are retrieved even from children tags\n",
    "    except AttributeError as e:  # if there is not such a tag exists\n",
    "        for tag in soup.findAll(text=re.compile(r'.*?copyright.*?',re.I)):  \n",
    "            if tag.parent.name in ['div','span', 'p','li','ul','small','a']:   # look for tags which are commonly ones used for copyright info whose texts match with either of the two strings. To recall the tag containing the texts, use \"parent\" tag attribute\n",
    "                copyrightTexts = tag.parent.text\n",
    "                break\n",
    "        if copyrightTexts == '':\n",
    "            symbol = u'\\N{COPYRIGHT SIGN}'.encode('utf-8')\n",
    "            symbol = symbol.decode('utf-8')\n",
    "            pattern = r'' + symbol\n",
    "            for tag in soup.findAll(text=re.compile(pattern)):\n",
    "                copyrightTexts = tag.parent.text\n",
    "                break             \n",
    "    if copyrightTexts != '':\n",
    "        pattern = r'' + str(domainIdentity)\n",
    "        if re.search(pattern,str(copyrightTexts),re.I):\n",
    "            domainInCopyright = 'Yes'\n",
    "        else:\n",
    "            domainInCopyright = 'No'\n",
    "    else:\n",
    "        domainInCopyright = 'Null'  # copyright info was not found in the webpage\n",
    "    return domainInCopyright\n",
    "\n",
    "\n",
    "def canonicalURL(URL,soup,mainDomain,freeDomains,TLDs):\n",
    "    try:\n",
    "        canonicalURL = soup.find('link', attrs={'rel':re.compile(\"canonical\", re.I)})['href']    # get a canonical URL\n",
    "        if URL == canonicalURL:\n",
    "            domainInCanonical = 'Yes'\n",
    "        elif re.search (r'https?://.*?',canonicalURL, re.I) or re.search (r'//.*?',canonicalURL, re.I) :    # if canonicalURL is assigned as a relative URL (path)\n",
    "            FQDN,domainIdentity2,mainDomain2,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed = getDomainIdentity(freeDomains,canonicalURL,TLDs)   # get a mainDomain of canonical URL\n",
    "            if mainDomain == mainDomain2:  # if main domains of both webpage's URL and canonical URL match\n",
    "               domainInCanonical = 'Yes'\n",
    "            else:\n",
    "               domainInCanonical = 'No'\n",
    "        else:   \n",
    "            if canonicalURL != '':\n",
    "                domainInCanonical = 'Yes'\n",
    "            else:   \n",
    "                domainInCanonical = 'Void'\n",
    "    except TypeError as e:\n",
    "        domainInCanonical = 'Null'   # means canonical URL was not found\n",
    "    return domainInCanonical\n",
    "\n",
    "\n",
    "def alternateURL(URL,soup,mainDomain,freeDomains,TLDs):\n",
    "    try:\n",
    "        alternateURL = soup.find('link', attrs={'rel':re.compile(\"alternate\", re.I)})['href'] # get an alternate URL out of many possible, an assumption is all URLs will have the same domain name\n",
    "        if URL == alternateURL:\n",
    "            domainInAlternate='Yes'\n",
    "        elif re.search (r'https?://.*?',alternateURL, re.I) or re.search (r'//.*?',alternateURL, re.I):  # if alternateURL is assigned as a relative URL (path)\n",
    "            QDN,domainIdentity2,mainDomain2,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed = getDomainIdentity(freeDomains,alternateURL,TLDs)   # get a mainDomain of alternate URL\n",
    "            if mainDomain == mainDomain2:  # if the main domains of both webpage's URL and alternate URL match\n",
    "               domainInAlternate = 'Yes'\n",
    "            else:\n",
    "               domainInAlternate = 'No'\n",
    "        else:  # re.search (r'./.*?',alternateURL, re.I) or re.search (r'../.*?',alternateURL, re.I) or re.search (r'/',alternateURL, re.I) or re.search (r'/.*?',alternateURL, re.I)  or re.search (r'#.*?',alternateURL, re.I) or re.search (r'javascript:;',alternateURL, re.I) or re.search (r'javascript:void(0);',alternateURL, re.I)\n",
    "            if alternateURL != '':\n",
    "                domainInAlternate = 'Yes'\n",
    "            else:\n",
    "                domainInAlternate = 'Void'\n",
    "    except TypeError as e:\n",
    "        domainInAlternate = 'Null'   # means alternate URL was not found\n",
    "    return domainInAlternate\n",
    "\n",
    "\n",
    "def mostCommonItem(List):  \n",
    "    popularItem = Counter(List).most_common(1)[0][0]  # (1) means return only one most common item. If there are several that are matching, the one with the lowest list index will be returned. [0][1] will return number of times of appearance\n",
    "    return popularItem\n",
    "\n",
    "    \n",
    "def getHyperlinkDominantDomain(soup,freeDomains,TLDs,mainDomain):\n",
    "    mainDomainList = []\n",
    "    totalLinks = 0\n",
    "    voidLinks = 0\n",
    "    samePageLinks = 0\n",
    "    hyperlinkList = []\n",
    "    hyperlinks = soup.find_all()  \n",
    "    for link in hyperlinks:\n",
    "        linkURL = link.get('href')\n",
    "        if linkURL is not None:\n",
    "            linkURL.lower()\n",
    "            totalLinks = totalLinks + 1\n",
    "            hyperlinkList.append(linkURL)\n",
    "            if linkURL == '' or linkURL == ' '  or  linkURL == 'javascript:void(0)'  :\n",
    "                voidLinks = voidLinks + 1\n",
    "                mainDomain2 = 'Null'\n",
    "            elif re.search (r'/',linkURL, re.I) or re.search (r'./',linkURL, re.I) or re.search (r'../',linkURL, re.I) :\n",
    "                mainDomain2 = mainDomain\n",
    "            elif re.search (r'https?://.*?',linkURL, re.I) or re.search (r'//.*?',linkURL, re.I) :\n",
    "                FQDN,domainIdentity2,mainDomain2,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed=getDomainIdentity(freeDomains,linkURL,TLDs)\n",
    "            elif re.search (r'#.*?',linkURL, re.I) :\n",
    "                samePageLinks = samePageLinks + 1\n",
    "                mainDomain2 = mainDomain\n",
    "            # links with a '/.......' format which are likely to be the most common ones\n",
    "            else:     # elif (re.search (r'https?://.*?',linkURL, re.I) is None) and (re.search (r'#.*?',linkURL, re.I) is None) and (re.search (r'javascript:;',linkURL, re.I) is None) and (re.search (r'javascript:void(0);',linkURL, re.I) is None) and (re.search (r'/',linkURL, re.I) is None):\n",
    "                mainDomain2 = mainDomain\n",
    "            mainDomainList.append(mainDomain2)\n",
    "    if mainDomainList:   # if at least one hyperlink was found\n",
    "        dominantDomain = mostCommonItem(mainDomainList)\n",
    "    else:    # if no hyperlink was found\n",
    "        dominantDomain = 'Null'\n",
    "    return dominantDomain,totalLinks,voidLinks,samePageLinks,hyperlinkList\n",
    "\n",
    "\n",
    "def foreignFormHandler(soup,mainDomain,dominantDomain,freeDomains,TLDs):\n",
    "    FHList = []\n",
    "    FHDomainList = []\n",
    "    for tag in soup.findAll('form', attrs={'method':[re.compile(\"post\", re.I), re.compile(\"get\", re.I)]}) :   # either method is POST or GET\n",
    "        if tag.get('action') is not None:\n",
    "            FH = tag.get('action')\n",
    "            if re.search (r'//.*?',FH, re.I):\n",
    "                FQDN,domainIdentity2,FHDomain,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed = getDomainIdentity(freeDomains,FH,TLDs)  \n",
    "                if  dominantDomain != 'Null' :   \n",
    "                    if (FHDomain == mainDomain) and (FHDomain == dominantDomain):\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'\n",
    "                else:\n",
    "                    if FHDomain == mainDomain :\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'             \n",
    "            elif re.search (r'/.*?',FH, re.I) or FH == '' or FH == 'self' or re.search (r'javascript:;',FH, re.I) or re.search (r'javascript:void(0);',FH, re.I) or re.search (r'./.*?',FH, re.I) or re.search (r'../.*?',FH, re.I) or re.search (r'[^/].*?',FH, re.I) :  # the url starts with one / only (the second character is not a /) or assigned no value or self or javascript based void/null expressions\n",
    "                FHDomain = mainDomain\n",
    "                if  dominantDomain != 'Null' :      \n",
    "                    if FHDomain == dominantDomain:\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'    \n",
    "                else:\n",
    "                    formHandlerStatus = 'Internal'    \n",
    "            else:\n",
    "                FQDN,domainIdentity2,FHDomain,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed = getDomainIdentity(freeDomains,FH,TLDs)\n",
    "                if  dominantDomain != 'Null' : \n",
    "                    if (FHDomain == mainDomain) and (FHDomain == dominantDomain):\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'\n",
    "                else:\n",
    "                    if FHDomain == mainDomain :\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'\n",
    "        elif tag.get('action') is None:  # some of the forms may not include action attribute at all (meaning the FH is the same as that of a webpage)\n",
    "            FHDomain = mainDomain\n",
    "            if  dominantDomain != 'Null' : \n",
    "                if FHDomain == dominantDomain:\n",
    "                    formHandlerStatus = 'Internal'\n",
    "                else:\n",
    "                    formHandlerStatus = 'External'\n",
    "            else:\n",
    "                formHandlerStatus = 'Internal'\n",
    "        FHList.append(formHandlerStatus)\n",
    "        FHDomainList.append(FHDomain)\n",
    "             \n",
    "    for tag in soup.findAll('form'):  # some of the forms may not include a method but may have an action attr (default method is GET)\n",
    "        if tag.get('method') is None and tag.get('action') is not None:\n",
    "            FH = tag.get('action')\n",
    "            if re.search (r'//.*?',FH, re.I):\n",
    "                FQDN,domainIdentity2,FHDomain,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed=getDomainIdentity(freeDomains,FH,TLDs)\n",
    "                if  dominantDomain != 'Null' : \n",
    "                    if (FHDomain == mainDomain) and (FHDomain == dominantDomain):\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus='External'\n",
    "                else:\n",
    "                    if FHDomain == mainDomain :\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus='External'\n",
    "            elif re.search (r'/.*?',FH, re.I) or FH == '' or FH == 'self' or re.search (r'javascript:;',FH, re.I) or re.search (r'javascript:void(0);',FH, re.I) or re.search (r'./.*?',FH, re.I) or re.search (r'../.*?',FH, re.I) or re.search (r'[^/].*?',FH, re.I) :  # the url starts with one / only (the second character is not a /) or assigned no value or self or javascript based void/null expressions\n",
    "                FHDomain = mainDomain\n",
    "                if  dominantDomain != 'Null' : \n",
    "                    if FHDomain == dominantDomain:\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'    \n",
    "                else:     \n",
    "                    formHandlerStatus = 'Internal'\n",
    "            else:\n",
    "                FQDN,domainIdentity2,FHDomain,URL_path,freeDomainUsed,FREEDomain,IPAddressUsed,IPAddress,PortNoUsed,PortNo,ccTLDUsed,ccTLD,gTLDUsed = getDomainIdentity(freeDomains,FH,TLDs)\n",
    "                if  dominantDomain != 'Null' : \n",
    "                    if (FHDomain == mainDomain) and (FHDomain == dominantDomain):\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'\n",
    "                else:\n",
    "                    if FHDomain == mainDomain :\n",
    "                        formHandlerStatus = 'Internal'\n",
    "                    else:\n",
    "                        formHandlerStatus = 'External'\n",
    "        elif tag.get('method') is None and tag.get('action') is None:   # some of the forms may not include both method and action attr (so default methos is GET and the FH is the same webpage)\n",
    "            FHDomain = mainDomain\n",
    "            if  dominantDomain != 'Null' : \n",
    "                if FHDomain == dominantDomain:\n",
    "                    formHandlerStatus = 'Internal'\n",
    "                else:\n",
    "                    formHandlerStatus = 'External'    \n",
    "            else:\n",
    "                formHandlerStatus = 'Internal'\n",
    "        FHList.append(formHandlerStatus)\n",
    "        FHDomainList.append(FHDomain)\n",
    "         \n",
    "    if len(FHList) > 0:\n",
    "        if FHList.count('External') > FHList.count('Internal'):   # if there are more than one form and total external action URLs are more than the internal ones\n",
    "            formHandlerStatus = 'External'\n",
    "        else:\n",
    "            formHandlerStatus = 'Internal'\n",
    "    else:\n",
    "        formHandlerStatus = 'Null'    # some webpages  use javascript instead of html forms to send data\n",
    "    FHDomainList = list(set(FHDomainList)) # remove duplicates in a list\n",
    "    return formHandlerStatus,FHDomainList\n",
    "\n",
    "\n",
    "def checkURLEncoding(FQDN,URL_path):\n",
    "    domainEncoded = 'No'\n",
    "    if len(re.findall(r'(%[0-9a-z][0-9a-z])',FQDN)) > 0:  # each URL encoded character is represented by % followed by hexadecimal digits (two numbers or letters or mixture of them).\n",
    "        domainEncoded = 'Yes'\n",
    "    pathEncodedCharacters = len(re.findall(r'(%[0-9a-z][0-9a-z])',URL_path))\n",
    "    return domainEncoded,pathEncodedCharacters\n",
    "\n",
    "\n",
    "def checkRedirectionCharacter(URL):\n",
    "    redirectionCharacter = 'No'\n",
    "    if re.search(r'.*?@.*?|.*?%40.*?',URL):  # check for the existence of the symbol @ or equivalent hexadecimal number\n",
    "        redirectionCharacter = 'Yes'\n",
    "    return redirectionCharacter\n",
    "    \n",
    "\n",
    "def domainOutPosition(URL,FQDN,URL_path,TLDs):\n",
    "    domainOutPosition = 'No'\n",
    "    if re.search(r'(https://)',URL):\n",
    "        if len(re.findall(r'(https://)',URL)) > 1:\n",
    "            domainOutPosition = 'Yes'\n",
    "        if URL.find('https') != 0:  # if https is not at the first position of the URL\n",
    "            domainOutPosition = 'Yes'\n",
    "    if domainOutPosition == 'No':\n",
    "        if re.search(r'(http://)',URL):\n",
    "            if len(re.findall(r'(http://)',URL)) > 1:\n",
    "                domainOutPosition = 'Yes'\n",
    "            if URL.find('http') != 0:  \n",
    "                domainOutPosition = 'Yes'\n",
    "    if domainOutPosition == 'No':\n",
    "        if re.search(r'(www)',URL):\n",
    "            if len(re.findall(r'(www)',URL)) > 1:\n",
    "                domainOutPosition = 'Yes'\n",
    "            else:\n",
    "                URL2 = URL.split('/',2)[2]  # remove URL prefix http:// or https://\n",
    "                if URL2.find('www') != 0:   # www should start at position 0 after removing a URL prefix\n",
    "                    domainOutPosition = 'Yes'\n",
    "    # check if a TLD exists in an unusual position in the domain\n",
    "    if domainOutPosition == 'No':\n",
    "        if re.search(r'.*?[:]\\d{2,}',FQDN):  # check if there is a port no\n",
    "            FQDN = FQDN.split(':')[0]\n",
    "        FQDN_parts = FQDN.split('.')\n",
    "        n = len(FQDN_parts)\n",
    "        if n >= 4:\n",
    "            for tld in TLDs:\n",
    "                tld = tld[0].split('.')[1]   # remove the dot\n",
    "                if tld in FQDN_parts[:-2] and tld not in FQDN_parts[0] :  # check with all separated parts of the domain except the last two and it shouldnt be in the first part\n",
    "                    domainOutPosition = 'Yes'\n",
    "                    #print('A', tld)\n",
    "                    break\n",
    "    # check if a TLD exists in the URL path\n",
    "    if domainOutPosition == 'No' and URL_path != '':\n",
    "        for tld in TLDs:\n",
    "            tld1 = tld[0] + '.'\n",
    "            tld2 = tld[0] + '/'\n",
    "            tld3 = tld[0] + '-'\n",
    "            if   URL_path.find(tld1) != -1:    #  find returns -1 if the substring does not exist,FHDomain otherwise  returns its position in the string\n",
    "                domainOutPosition = 'Yes'\n",
    "                break\n",
    "            if   URL_path.find(tld2) != -1:    #  find returns -1 if the substring does not exist,FHDomain otherwise  returns its position in the string\n",
    "                domainOutPosition = 'Yes'\n",
    "                break    \n",
    "            if   URL_path.find(tld3) != -1:    #  find returns -1 if the substring does not exist,FHDomain otherwise  returns its position in the string\n",
    "                domainOutPosition = 'Yes'\n",
    "                break  \n",
    "            if  URL_path.endswith(tld[0]) :    #  find returns -1 if the substring does not exist,FHDomain otherwise  returns its position in the string\n",
    "                domainOutPosition = 'Yes'\n",
    "                break           \n",
    "    return domainOutPosition\n",
    "\n",
    "        \n",
    "def numberOfDots(FQDN,URL_path):\n",
    "    noDotsFQDN = FQDN.count('.')\n",
    "    noDotsURLPath = URL_path.count('.')\n",
    "    return noDotsFQDN,noDotsURLPath\n",
    "\n",
    "\n",
    "def URLObfuscationCharacters(FQDN,URL_path):\n",
    "    dashFQDN = FQDN.count('-')\n",
    "    underscoreFQDN = FQDN.count('_')\n",
    "    equalFQDN = FQDN.count('=')\n",
    "    obfuscFQDN = dashFQDN + underscoreFQDN + equalFQDN\n",
    "    dashPath = URL_path.count('-')\n",
    "    underscorePath = URL_path.count('_')\n",
    "    equalPath = URL_path.count('=')\n",
    "    obfuscPath = dashPath + underscorePath + equalPath\n",
    "    return obfuscFQDN,obfuscPath\n",
    "\n",
    "       \n",
    "def determineStandardPort(URLPrefix,PortNo):\n",
    "    if URLPrefix == 'http' :\n",
    "        if PortNo == '80' :\n",
    "            standardPort = 'Yes'\n",
    "        else:\n",
    "            standardPort = 'No'\n",
    "    if URLPrefix == 'https' :\n",
    "        if PortNo == '443' :\n",
    "            standardPort = 'Yes'\n",
    "        else:\n",
    "            standardPort = 'No'\n",
    "    return standardPort\n",
    "\n",
    "    \n",
    "def checkURLLength(URL,FQDN,URL_path):\n",
    "    lengthFQDN  = len(FQDN)  # length of the FQDN (without including URL prefix)\n",
    "    lengthPath = len(URL_path)\n",
    "    noSlashes = URL.count('/')   \n",
    "    return lengthFQDN,lengthPath,noSlashes\n",
    "    \n",
    "\n",
    "def domainWHOISrecords(mainDomain):  # the first WHOIS approach which uses whois library\n",
    "    try:\n",
    "        answer = whois.whois(mainDomain)   \n",
    "        if type(answer.expiration_date) == list:  # single or multiple dates (in a list format) could be returned\n",
    "            answer.expiration_date = answer.expiration_date[0]\n",
    "        else:\n",
    "            answer.expiration_date = answer.expiration_date\n",
    "        timedelta1 = answer.expiration_date - datetime.now()  # determine if the expiration date is still valid       \n",
    "        if type(answer.creation_date) == list:  # single or multiple dates (in a list format) could be returned\n",
    "            answer.creation_date = answer.creation_date[0]\n",
    "        else:\n",
    "            answer.creation_date = answer.creation_date\n",
    "        timedelta2 = datetime.now() - answer.creation_date\n",
    "        domainAge = timedelta2.days  # timedelta returns days, hours,minutes and does not return weeks or months. Here domain age is in days.\n",
    "        #domainAge=round((domainAge/7),2)  # time in weeks, rounded to 2 decimal places\n",
    "        if timedelta1.days < 0:\n",
    "            domainValidity = 'No'\n",
    "        else:\n",
    "            domainValidity = 'Yes'\n",
    "    except whois.parser.PywhoisError as e:   # if there is missing whois records for the domain\n",
    "        domainValidity = 'Unknown'\n",
    "        domainAge = -1\n",
    "    except socket.timeout as e:   # the server delays in responding\n",
    "        domainValidity = 'Unknown'\n",
    "        domainAge = -1\n",
    "    except socket.gaierror as e:   # the WHOIS db used by this approach is not reachable\n",
    "        domainValidity = 'Unknown'\n",
    "        domainAge = -1\n",
    "    except TypeError as e :   \n",
    "        domainValidity = 'Unknown'\n",
    "        domainAge = -1\n",
    "    except ConnectionResetError as e :   \n",
    "        domainValidity = 'Unknown'\n",
    "        domainAge = -1\n",
    "    return domainValidity, domainAge\n",
    "\n",
    "    \n",
    "def verifySSLCertificate(URL,FQDN,headers):  # NOTE; subdomain may use different certificate from the main domain. So we have to use a FQDN to query for a certificate             \n",
    "    URLPrefix = getURLPrefix(URL)\n",
    "    if URLPrefix == 'https'  :\n",
    "        certificateExist = 'Yes'\n",
    "        certificateVerificationErrorType = 'Null'  \n",
    "        getCertificateError = 'No'\n",
    "        try:\n",
    "            requests.get(URL,headers=headers)  # checks for matched hostname, self signing, valid date and known root CA attributes of the certificate\n",
    "        except requests.exceptions.SSLError as e:  # certificate errors detected by the requests lib\n",
    "            e = str(e)\n",
    "            if re.search(r'hostname .*? doesn.t match',e,re.I):\n",
    "                certificateVerificationErrorType = 'Host name mismatching'\n",
    "            elif re.search(r'bad handshake',e,re.I):\n",
    "                certificateVerificationErrorType = 'Bad handshake'\n",
    "            elif re.search(r'handshake failure',e,re.I):\n",
    "                certificateVerificationErrorType = 'Out dated cipher'\n",
    "            elif re.search(r'SSL_NEGATIVE_LENGTH',e,re.I):\n",
    "                certificateVerificationErrorType = 'SSL version or cipher mismatch'\n",
    "            elif re.search(r'certificate verify failed',e,re.I):\n",
    "                certificateVerificationErrorType = 'Self signed, expired, incomplete CA chain or untrusted root CA'\n",
    "            else:\n",
    "                certificateVerificationErrorType = 'Others'     \n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            certificateVerificationErrorType = 'Others'               \n",
    "        try:\n",
    "            cert_str = ssl.get_server_certificate((FQDN,443))   # loads the certificate from a webpage host/server\n",
    "            #cert_str = ssl.get_server_certificate((FQDN,443), ssl_version=ssl.PROTOCOL_TLSv1, ca_certs=None)   # loads the certificate from a webpage host/server of a specific version\n",
    "            pem_data = cert_str.encode()  # converting string into bytes using default 'utf-8' (Python 3.x) as pem_data should always be in bytes\n",
    "            cert = x509.load_pem_x509_certificate(pem_data, default_backend())   # loading from the host server the certificate content in X509 format\n",
    "            #pem_crl_data = ssl.DER_cert_to_PEM_cert(DER_cert_bytes) # should convert .crl (in DER format) to .pem\n",
    "            #crl = x509.load_pem_x509_crl(pem_crl_data, default_backend())   #loading the Certificate Revocation List (CRL)\n",
    "            cert_policies = cert.extensions.get_extension_for_oid(ExtensionOID.CERTIFICATE_POLICIES)    #extracts policy info\n",
    "            for policy in cert_policies.value :  # policies may range from 1 to 3 policies\n",
    "                oid = str(policy.policy_identifier).split('=',2)[1].split(',',1)[0]\n",
    "                oidNumbers = oid.split('.')\n",
    "                if len(oidNumbers) == 6 or len(oidNumbers) == 5 :\n",
    "                    OID = oid\n",
    "                    break\n",
    "                else :\n",
    "                    OID = 'Null'\n",
    "        except x509.extensions.ExtensionNotFound as e:   # the certificate exists but does not contain/return  extensions \n",
    "            OID = 'No Policies' \n",
    "        except ssl.SSLError as e:   # ssl.get_server_certificate fails to load the cert due to handshake error\n",
    "            getCertificateError = 'Yes'    # error due ssl.get_server_certificate()\n",
    "            certificateVerificationErrorType = 'Handshake (TLSv1 alert internal) error'\n",
    "        except ConnectionResetError as e:   # error due connection failure of ssl.get_server_certificate()\n",
    "            getCertificateError = 'Yes'    # error due connection failure of ssl.get_server_certificate()\n",
    "            certificateVerificationErrorType = 'Connection forcibly closed by the host server'\n",
    "        except ConnectionRefusedError as e:   # error due connection failure of ssl.get_server_certificate()\n",
    "            getCertificateError = 'Yes'    # error due connection failure of ssl.get_server_certificate()\n",
    "            certificateVerificationErrorType = 'Connection refused by the host server'\n",
    "        except OSError as e:   # error due connection failure of ssl.get_server_certificate()\n",
    "            getCertificateError = 'Yes'    # error due connection failure of ssl.get_server_certificate()\n",
    "            certificateVerificationErrorType = 'OS error'\n",
    "        if getCertificateError == 'No'  :   \n",
    "            try:\n",
    "                organizationName = cert.subject.get_attributes_for_oid(NameOID.ORGANIZATION_NAME)[0].value\n",
    "            except IndexError as e:\n",
    "                organizationName = 'Null'\n",
    "            try:\n",
    "                countryName = cert.subject.get_attributes_for_oid(NameOID.COUNTRY_NAME)[0].value\n",
    "            except IndexError as e:\n",
    "                countryName = 'Null'\n",
    "            try:\n",
    "                jurisdictionCountryName = cert.subject.get_attributes_for_oid(NameOID.JURISDICTION_COUNTRY_NAME)[0].value\n",
    "            except IndexError as e:\n",
    "               jurisdictionCountryName = 'Null'              \n",
    "        if certificateVerificationErrorType != 'Null' :\n",
    "            OID = 'N/A' \n",
    "            organizationName = 'N/A' \n",
    "            countryName = 'N/A' \n",
    "            jurisdictionCountryName = 'N/A'        \n",
    "    elif URLPrefix == 'http'  :  \n",
    "        certificateExist = 'No' \n",
    "        certificateVerificationErrorType = 'N/A'\n",
    "        OID = 'N/A' \n",
    "        organizationName = 'N/A' \n",
    "        countryName = 'N/A' \n",
    "        jurisdictionCountryName = 'N/A' \n",
    "    return certificateExist,OID,organizationName,countryName,jurisdictionCountryName,certificateVerificationErrorType\n",
    "\n",
    "\n",
    "def checkSSLCertificateType(certificateExist,OID,organizationName,jurisdictionCountryName,certificateVerificationErrorType): \n",
    "    if certificateExist == 'Yes'  and certificateVerificationErrorType == 'Null' : \n",
    "        if OID != 'Null' and OID != 'No Policies' :\n",
    "            oidNumbers = OID.split('.')\n",
    "            if len(oidNumbers) == 6 :\n",
    "                if OID.endswith('1') :\n",
    "                    certificateType = 'DV'\n",
    "                elif OID.endswith('2') :\n",
    "                    certificateType = 'OV'\n",
    "            elif len(oidNumbers) == 5 :\n",
    "                if OID.endswith('1') :\n",
    "                    certificateType = 'EV'\n",
    "        else:\n",
    "            if (organizationName == 'Null'  or organizationName == 'N/A' ) and (jurisdictionCountryName == 'Null'  or jurisdictionCountryName == 'N/A' ) :\n",
    "                certificateType = 'DV'\n",
    "            elif (organizationName != 'Null'  or organizationName != 'N/A')  and (jurisdictionCountryName == 'Null'  or jurisdictionCountryName == 'N/A' ) :\n",
    "                certificateType = 'OV'\n",
    "            elif (organizationName != 'Null'  or organizationName != 'N/A') and (jurisdictionCountryName != 'Null'  or jurisdictionCountryName != 'N/A' ) :\n",
    "                certificateType = 'EV'\n",
    "    else:\n",
    "        certificateType = 'Null'\n",
    "    return certificateType\n",
    "      \n",
    "        \n",
    "def getIPAdresses(query):   # query can be a FQDN (subdomain) or main domain\n",
    "    try:\n",
    "        IPs = socket.gethostbyname_ex(query)  # returns alias hostnames and resolved one or multiple IP addresses (v4 only) in the format(hostname, list of aliases, list of IP addresses). For v4 and v6, use  socket.getaddrinfo()\n",
    "        IPList = IPs[2] \n",
    "    except socket.gaierror as e:   # if IP resolution has failed\n",
    "        IPList = []\n",
    "    return IPList    # IPs returned in a list format\n",
    "\n",
    "\n",
    "def reverseIPLookup(IP):   # IPv4\n",
    "    try:\n",
    "       hostInfo = socket.gethostbyaddr(IP)   # return data in form of (hostname, list of aliases, list of IP addresses)\n",
    "       hostname =  hostInfo[0]\n",
    "    except socket.herror as e:   # if DNS lookup has failed\n",
    "       hostname = '' \n",
    "    return hostname\n",
    "    \n",
    "\n",
    "def getIPv4and6(query): # query can be a FQDN (subdomain) or main domain\n",
    "    IPList = []\n",
    "    IPVersionList = []\n",
    "    try:\n",
    "        #IPinfo = socket.getaddrinfo(query,None,socket.AF_INET6) # query IPv6 only\n",
    "        IPinfo = socket.getaddrinfo(query,None) # query IPv4 and v6\n",
    "        for IP in IPinfo :\n",
    "            IPList.append(IP[4][0])\n",
    "            IPFamily = str(IP[0])\n",
    "            IPFamily = IPFamily.split('.')[1]\n",
    "            if IPFamily == 'AF_INET':\n",
    "                version = 4\n",
    "            if IPFamily == 'AF_INET6':\n",
    "                version = 6\n",
    "            IPVersionList.append(version)\n",
    "    except socket.gaierror as e: # if IP resolution has failed\n",
    "        pass\n",
    "    return IPList,IPVersionList    # IPs and their versions are returned in their corresponding lists in the same order\n",
    "\n",
    "\n",
    "def getGeoCountry(IP):\n",
    "    reader = geoip2.database.Reader('GeoLite2-City_20201215/GeoLite2-City.mmdb')  # this is a relative path, the folder being in the same one with the one that is having app coding files\n",
    "    response = reader.city(IP)\n",
    "    geoCountry=response.country.iso_code\n",
    "    reader.close()\n",
    "    return geoCountry\n",
    "\n",
    "\n",
    "def verifyRegisteredCountry(DomainIPList,ccTLDUsed,ccTLD,gTLDUsed,certificateType,jurisdictionCountryName,countryName):\n",
    "    countryMatch = 'No'\n",
    "    if ccTLDUsed == 'Yes':\n",
    "        ccTLD = ccTLD.split('.')[1]\n",
    "        if ccTLD == 'uk': # the official ISO country code for UK is GB (returned by geoip2 and certificates) and not UK\n",
    "            ccTLD = 'gb'\n",
    "        if certificateType == 'N/A' or certificateType == 'DV': # match a ccTLD and the actual hosting country           \n",
    "            for IP in DomainIPList:\n",
    "                geoCountry = getGeoCountry(IP)\n",
    "                if geoCountry.lower() == ccTLD:\n",
    "                    countryMatch = 'Yes'\n",
    "                    break\n",
    "        if certificateType == 'EV': # matching ccTLD and the actual country the business registered in\n",
    "            for IP in DomainIPList:\n",
    "                geoCountry = getGeoCountry(IP)\n",
    "                if geoCountry.lower() == ccTLD and geoCountry.lower() == jurisdictionCountryName.lower():\n",
    "                    countryMatch = 'Yes'\n",
    "                    break\n",
    "        if certificateType == 'OV': # matching ccTLD and the actual country the business registered in\n",
    "            for IP in DomainIPList:\n",
    "                geoCountry = getGeoCountry(IP)\n",
    "                if geoCountry.lower() == ccTLD and geoCountry.lower() == countryName.lower():\n",
    "                    countryMatch = 'Yes'\n",
    "                    break\n",
    "    if gTLDUsed == 'Yes':\n",
    "        if certificateType == 'EV':\n",
    "            for IP in DomainIPList:\n",
    "                geoCountry = getGeoCountry(IP)\n",
    "                if geoCountry == jurisdictionCountryName:# both returned in capital letters\n",
    "                    countryMatch = 'Yes'\n",
    "                    break\n",
    "        if certificateType == 'OV':\n",
    "            for IP in DomainIPList:\n",
    "                geoCountry = getGeoCountry(IP)\n",
    "                if geoCountry == countryName: # both returned in capital letters\n",
    "                    countryMatch = 'Yes'\n",
    "                    break \n",
    "        if certificateType == 'N/A' or certificateType == 'DV':\n",
    "            countryMatch = 'Unknown'  \n",
    "    return countryMatch\n",
    "\n",
    "\n",
    "def googleCustomSearchEngine(query):  # 100 queries per day and max of 10 results per query for free\n",
    "    cse_id = '007558115989444180959:sivyr_cntqk'  # Custom Search Engine ID\n",
    "    #api_key = 'AIzaSyAojv4t1OR8SISplrTBmw_JSaV7SuvfvSE'  # Google API key from BCU billed Google cloud account - tom.nagunwa@gmail.com\n",
    "    api_key ='AIzaSyBnrYcOo3W33QnGPWbhX9htyPxwZkGMweg'\n",
    "    googleResults = []\n",
    "    service = build(\"customsearch\",\"v1\",developerKey=api_key)\n",
    "    try:\n",
    "        #data=service.cse().list(q=query,cx=cse_id,cr=\"countryUK\",num=5).execute()  # search with global perspective,returns answers as dictionary \n",
    "        data = service.cse().list(q=query,cx=cse_id,num=10).execute()\n",
    "        googleResultsReturned = 'Yes'        \n",
    "        for v in data['items']:\n",
    "            googleResults.append(v['link'])\n",
    "    except KeyError as e:  # if no results are returned\n",
    "        googleResultsReturned = 'No'\n",
    "    return googleResultsReturned,googleResults\n",
    "    \n",
    "               \n",
    "def bingSearch(query): # limits 50 results per query (if the offset is 0)\n",
    "    bingResults = []  \n",
    "    url = 'https://api.cognitive.microsoft.com/bing/v7.0/search'\n",
    "    #payload={'q': query, 'count': '5','offset': '0','mkt':'en-gb'}  # limit the 5 first answers,search with UK perspective\n",
    "    #payload = {'q': query, 'count': '5','offset': '0'}\n",
    "    payload = {'q': query, 'count': '49','offset': '0'}\n",
    "    headers = {'Ocp-Apim-Subscription-Key': '6736c1658a7e4bb7b026935d8fb747a3'}\n",
    "    try:\n",
    "        answers = requests.get(url,params=payload,headers=headers) \n",
    "        data = answers.json() # returns answers in JSON \n",
    "        bingResultsReturned = 'Yes'\n",
    "        for v in data[\"webPages\"][\"value\"]:\n",
    "            bingResults.append(v[\"url\"])\n",
    "    except KeyError as e:  # if no results are returned\n",
    "        bingResultsReturned = 'No'\n",
    "    return bingResultsReturned,bingResults\n",
    "        \n",
    "\n",
    "def checkURLSearchEngineReputation(URL,googleResultsReturned,bingResultsReturned,googleResults,bingResults):\n",
    "    if googleResultsReturned == 'Yes' and bingResultsReturned == 'Yes':\n",
    "        if URL in googleResults and URL in bingResults:\n",
    "            URLMatch = 'Yes'\n",
    "            engine = 'Google, Bing'\n",
    "        elif URL in googleResults and URL not in bingResults:\n",
    "            URLMatch = 'Yes'\n",
    "            engine = 'Google'\n",
    "        elif URL not in googleResults and URL in bingResults:\n",
    "            URLMatch = 'Yes'\n",
    "            engine = 'Bing'\n",
    "        elif URL not in googleResults and URL not in bingResults:\n",
    "            URLMatch='No'\n",
    "            engine='Null'   \n",
    "    elif googleResultsReturned == 'Yes' and bingResultsReturned == 'No':\n",
    "        if URL in googleResults:\n",
    "            URLMatch = 'Yes'\n",
    "            engine = 'Google' \n",
    "        else:\n",
    "            URLMatch = 'No'\n",
    "            engine = 'Null'     \n",
    "    elif googleResultsReturned == 'No' and bingResultsReturned == 'Yes':  \n",
    "        if URL in bingResults:\n",
    "            URLMatch = 'Yes'\n",
    "            engine = 'Bing' \n",
    "        else:\n",
    "            URLMatch = 'No'\n",
    "            engine = 'Null'     \n",
    "    elif googleResultsReturned == 'No' and bingResultsReturned == 'No': \n",
    "        URLMatch = 'No'\n",
    "        engine = 'Null'\n",
    "    return URLMatch,engine\n",
    "\n",
    "\n",
    "def checkDomainFQDNSearchEngineReputation(mainDomain,FQDN,googleResultsReturned,bingResultsReturned,googleResults,bingResults):\n",
    "    FQDNMatch = 'No'\n",
    "    domainMatch = 'No'\n",
    "    if googleResultsReturned == 'Yes':\n",
    "        for url in googleResults:\n",
    "            domain = url.split('/',3)[2]\n",
    "            if FQDN == domain:\n",
    "                FQDNMatch = 'Yes'\n",
    "            if domain.endswith(mainDomain):\n",
    "                domainMatch = 'Yes' \n",
    "    if  FQDNMatch == 'No' or domainMatch == 'No':            \n",
    "        if bingResultsReturned == 'Yes':\n",
    "            for url in bingResults:\n",
    "                domain = url.split('/',3)[2]\n",
    "                if FQDN == domain:\n",
    "                    FQDNMatch = 'Yes'\n",
    "                if domain.endswith(mainDomain):\n",
    "                    domainMatch = 'Yes'\n",
    "    return domainMatch,FQDNMatch\n",
    "\n",
    "\n",
    "def checkBlacklistedIPs(hostIPList,domainIPList,cur):\n",
    "    FQDNBlacklistedIP = 'No'\n",
    "    domainBlacklistedIP = 'No'\n",
    "    blacklistedIPs = getBlacklistedIPs(cur)\n",
    "    FQDNBlacklistIPCounts = 0 # total appearances of all IPs in hostIPList in the blacklist\n",
    "    for IP in hostIPList:\n",
    "        for blackIP in blacklistedIPs:\n",
    "            if IP == blackIP[1]:\n",
    "                FQDNBlacklistedIP = 'Yes'\n",
    "                FQDNBlacklistIPCounts = FQDNBlacklistIPCounts + 1\n",
    "    if hostIPList != domainIPList:\n",
    "        domainBlacklistIPCounts = 0\n",
    "        for IP in domainIPList:\n",
    "            for blackIP in blacklistedIPs:\n",
    "                if IP == blackIP[1]:\n",
    "                    domainBlacklistedIP = 'Yes'\n",
    "                    domainBlacklistIPCounts = domainBlacklistIPCounts + 1\n",
    "    else:\n",
    "        domainBlacklistedIP = FQDNBlacklistedIP\n",
    "        domainBlacklistIPCounts = FQDNBlacklistIPCounts\n",
    "    return FQDNBlacklistedIP,domainBlacklistedIP,FQDNBlacklistIPCounts,domainBlacklistIPCounts\n",
    "        \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
